# awesome_video_person_reid
only focus on video person re-identification.

# TODO
I will update this repository in the near future.

## SOTA:
                            
|No.|Dataset  |Rank1   |mAP | Link  |
|:-----:|:-----:|:-----:|:-----:|:---:|
|1|PRID|__97.4%__|__Null__|[paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8675282)|
|2|iLIDS-VID|__92.0%__|__Null__|[paper[ICCV2021]](https://arxiv.org/pdf/2103.09013.pdf)|
|3|Mars|__91.4%__|__86.7%__|[paper[CVPR2021]](https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Spatial-Temporal_Correlation_and_Topology_Learning_for_Person_Re-Identification_in_Videos_CVPR_2021_paper.pdf)|
|4|DukeMTMC|__98.3%__|__97.4%__|[paper[ICCV2021]](https://github.com/WangYQ9/VideoReID_PSTA)|
|5|LS-VID|__84.6%__|__75.1%__|[paper[CVPR2021]](https://openaccess.thecvf.com/content/CVPR2021/papers/Hou_BiCnet-TKS_Learning_Efficient_Spatial-Temporal_Representation_for_Video_Person_Re-Identification_CVPR_2021_paper.pdf)|

## Leaderboard for 4 benchmarks
please refer to [LEADERBOARD.md](leaderboard.md) for the leaderboard on public benchmarks.

## Citation

If you find this repo useful, please kindly cite the following paper:
<pre>
@inproceedings{yu2024tf,
  title={TF-CLIP: Learning Text-Free CLIP for Video-Based Person Re-identification},
  author={Yu, Chenyang and Liu, Xuehu and Wang, Yingquan and Zhang, Pingping and Lu, Huchuan},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={7},
  pages={6764--6772},
  year={2024}
}
@inproceedings{liu2021watching, 
  title={Watching You: Global-guided Reciprocal Learning for Video-based Person Re-identification}, 
  author={Liu, Xuehu and Zhang, Pingping and Yu, Chenyang and Lu, Huchuan and Yang, Xiaoyun}, 
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  pages={13334--13343}, 
  year={2021} 
} 
@article{liu2023deeply,
  title={Deeply coupled convolution--transformer with spatial--temporal complementary learning for video-based person re-identification},
  author={Liu, Xuehu and Yu, Chenyang and Zhang, Pingping and Lu, Huchuan},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2023},
  publisher={IEEE}
}
@article{liu2021video,
  title={A Video Is Worth Three Views: Trigeminal Transformers for Video-based Person Re-identification},
  author={Liu, Xuehu and Zhang, Pingping and Yu, Chenyang and Lu, Huchuan and Qian, Xuesheng and Yang, Xiaoyun},
  journal={arXiv preprint arXiv:2104.01745},
  year={2021}
}
@inproceedings{gao2024part,
  title={Part Representation Learning with Teacher-Student Decoder for Occluded Person Re-Identification},
  author={Gao, Shang and Yu, Chenyang and Zhang, Pingping and Lu, Huchuan},
  booktitle={ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={2660--2664},
  year={2024},
  organization={IEEE}
}
@inproceedings{gao2023ped,
  title={Ped-Mix: Mix Pedestrians for Occluded Person Re-identification},
  author={Gao, Shang and Yu, Chenyang and Zhang, Pingping and Lu, Huchuan},
  booktitle={Chinese Conference on Pattern Recognition and Computer Vision (PRCV)},
  pages={265--277},
  year={2023},
  organization={Springer}
}
</pre>
