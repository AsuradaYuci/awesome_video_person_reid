# awesome_video_person_reid
only focus on video person re-identification

SOTA:
                            
|No.|Dataset  |Rank1   |mAP | Link  |
|:-----:|:-----:|:-----:|:-----:|:---:|
|1|PRID|__97.4%__|__Null__|[paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8675282)|
|2|iLIDS-VID|__92.0%__|__Null__|[paper[ICCV2021]](https://arxiv.org/pdf/2103.09013.pdf)|
|3|Mars|__91.4%__|__86.7%__|[paper[CVPR2021]](https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Spatial-Temporal_Correlation_and_Topology_Learning_for_Person_Re-Identification_in_Videos_CVPR_2021_paper.pdf)|
|4|DukeMTMC|__98.3%__|__97.4%__|[paper[ICCV2021]](https://github.com/WangYQ9/VideoReID_PSTA)|
|5|LS-VID|__84.6%__|__75.1%__|[paper[CVPR2021]](https://openaccess.thecvf.com/content/CVPR2021/papers/Hou_BiCnet-TKS_Learning_Efficient_Spatial-Temporal_Representation_for_Video_Person_Re-Identification_CVPR_2021_paper.pdf)|



## Citation

If you find this repo useful, please kindly cite the following paper:
<pre>
@inproceedings{liu2021watching, 
  title={Watching You: Global-guided Reciprocal Learning for Video-based Person Re-identification}, 
  author={Liu, Xuehu and Zhang, Pingping and Yu, Chenyang and Lu, Huchuan and Yang, Xiaoyun}, 
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  pages={13334--13343}, 
  year={2021} 
} 
@article{liu2021video,
  title={A Video Is Worth Three Views: Trigeminal Transformers for Video-based Person Re-identification},
  author={Liu, Xuehu and Zhang, Pingping and Yu, Chenyang and Lu, Huchuan and Qian, Xuesheng and Yang, Xiaoyun},
  journal={arXiv preprint arXiv:2104.01745},
  year={2021}
}
</pre>